{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6082f7c7",
   "metadata": {},
   "source": [
    "## Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c543aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf37e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f9a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/03 13:42:50 WARN Utils: Your hostname, me-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.42.129 instead (on interface ens33)\n",
      "23/10/03 13:42:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/03 13:42:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[8]\") \\\n",
    "            .appName(\"Higgs Twitter ETL\") \\\n",
    "            .config(\"spark.some.config.option\", \"some-value\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954a46da",
   "metadata": {},
   "source": [
    "## Reading edgelist files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0037d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b7d4c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14855842 2 \n",
      "\n",
      "+--------+--------+\n",
      "|follower|followed|\n",
      "+--------+--------+\n",
      "|       1|       2|\n",
      "|       1|       3|\n",
      "|       1|       4|\n",
      "|       1|       5|\n",
      "|       1|       6|\n",
      "+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('follower', IntegerType(), True), StructField('followed', IntegerType(), True)])\n",
    "socialDF = spark.read.csv('data/higgs-social_network.edgelist.gz', sep=\" \", schema=schema).dropna()\n",
    "print(socialDF.count(), len(socialDF.columns), '\\n')\n",
    "socialDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "266005b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328132 2 \n",
      "\n",
      "+---------+------+\n",
      "|retweeter|author|\n",
      "+---------+------+\n",
      "|   298960|105232|\n",
      "|    95688|  3393|\n",
      "|   353237| 62217|\n",
      "|     4974|  3571|\n",
      "|   241892|     8|\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "schema = StructType([StructField('retweeter', IntegerType(), True), StructField('author', IntegerType(), True)])\n",
    "retweetDF = spark.read.csv('data/higgs-retweet_network.edgelist.gz', sep=\" \", schema=schema).dropna()\n",
    "print(retweetDF.count(), len(socialDF.columns), '\\n')\n",
    "retweetDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2125d7e",
   "metadata": {},
   "source": [
    "## Spark SQL with dataframes API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c37f667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|user|num_followers|\n",
      "+----+-------------+\n",
      "| 148|          738|\n",
      "| 463|        10953|\n",
      "| 471|         1584|\n",
      "| 496|           49|\n",
      "| 833|            8|\n",
      "+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "followerCountDF = socialDF.groupBy('followed')\\\n",
    ".count()\\\n",
    ".withColumnRenamed('followed', 'user') \\\n",
    ".withColumnRenamed('count', 'num_followers')\\\n",
    ".fillna(0)\n",
    "\n",
    "followerCountDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1e10993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|  user|num_retweets|\n",
      "+------+------------+\n",
      "| 28664|         109|\n",
      "|172959|           1|\n",
      "|122128|           1|\n",
      "|102524|           1|\n",
      "| 63087|           1|\n",
      "+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "retweetCountDF = retweetDF\\\n",
    ".groupBy('author')\\\n",
    ".count()\\\n",
    ".withColumnRenamed('author', 'user') \\\n",
    ".withColumnRenamed('count', 'num_retweets')\\\n",
    ".fillna(0)\n",
    "\n",
    "retweetCountDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60c1975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+----+------------+-----------+\n",
      "|user|num_followers|user|num_retweets|filled_user|\n",
      "+----+-------------+----+------------+-----------+\n",
      "|   1|        16280|null|           0|          1|\n",
      "|   2|         4707|null|           0|          2|\n",
      "|   3|          137|null|           0|          3|\n",
      "|   4|         8643|   4|          77|          4|\n",
      "|   5|         2194|   5|          24|          5|\n",
      "|   6|        27088|   6|          83|          6|\n",
      "|   7|         2146|   7|          15|          7|\n",
      "|   8|        32106|   8|         841|          8|\n",
      "|   9|          567|null|           0|          9|\n",
      "|  10|        10204|null|           0|         10|\n",
      "+----+-------------+----+------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import asc, coalesce\n",
    "\n",
    "# Outer join the dataframes and create a filled user column that can be used as an index for both dfs\n",
    "userDF = followerCountDF\\\n",
    ".join(retweetCountDF, followerCountDF.user==retweetCountDF.user, 'outer')\\\n",
    ".na.fill({'num_followers': 0, 'num_retweets': 0})\n",
    "userDF = userDF.withColumn('filled_user', coalesce(followerCountDF['user'], retweetCountDF['user']))\n",
    "userDF.sort(asc('filled_user')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a294b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 115:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+\n",
      "|filled_user|num_followers|num_retweets|\n",
      "+-----------+-------------+------------+\n",
      "|          1|        16280|           0|\n",
      "|          2|         4707|           0|\n",
      "|          3|          137|           0|\n",
      "|          4|         8643|          77|\n",
      "|          5|         2194|          24|\n",
      "+-----------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "userDataDF = userDF.select('filled_user', 'num_followers', 'num_retweets').sort(asc('filled_user'))\n",
    "userDataDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032497aa",
   "metadata": {},
   "source": [
    "## Spark sql with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e94b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 212:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-------------+------------+\n",
      "|my_user|user|user|num_followers|num_retweets|\n",
      "+-------+----+----+-------------+------------+\n",
      "|      1|   1|null|        16280|        null|\n",
      "|      2|   2|null|         4707|        null|\n",
      "|      3|   3|null|          137|        null|\n",
      "|      4|   4|   4|         8643|          77|\n",
      "|      5|   5|   5|         2194|          24|\n",
      "+-------+----+----+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "socialDF.createOrReplaceTempView('social')\n",
    "retweetDF.createOrReplaceTempView('retweet')\n",
    "userdataDF2 = spark.sql(\n",
    "     \"\"\"\n",
    "     select\n",
    "     coalesce(follower_count.user, retweet_count.user) as my_user,\n",
    "     follower_count.user,\n",
    "     retweet_count.user,\n",
    "     follower_count.num_followers,\n",
    "     retweet_count.num_retweets\n",
    "     \n",
    "     from \n",
    "     (select \n",
    "     followed as user, \n",
    "     count(follower) as num_followers\n",
    "     from social\n",
    "     group by followed) as follower_count\n",
    "     \n",
    "     full outer join\n",
    "     \n",
    "     (select \n",
    "     author as user, \n",
    "     count(retweeter) as num_retweets\n",
    "     from retweet\n",
    "     group by author) as retweet_count\n",
    "     \n",
    "     on follower_count.user = retweet_count.user\n",
    "     order by my_user asc\n",
    "     \"\"\"\n",
    " )\n",
    "userdataDF2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12da4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
